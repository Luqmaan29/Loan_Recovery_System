"""
Main Script for Simple Loan Recommendation System
Demonstrates complete ML pipeline
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import sys
import os

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from simple_data_loader import SimpleDataLoader
from simple_model_trainer import SimpleModelTrainer

def main():
    """Run complete ML pipeline."""
    
    print("=" * 80)
    print("üè¶ SMART LOAN RECOMMENDATION SYSTEM")
    print("   Complete ML Pipeline Demonstration")
    print("=" * 80)
    
    # Step 1: Load Data
    print("\n" + "=" * 80)
    print("STEP 1: DATA LOADING")
    print("=" * 80)
    
    loader = SimpleDataLoader()
    data = loader.load_all_data()
    
    X_train, y_train = data['train']
    X_test, y_test = data['test']
    
    # Split training data into train and validation
    X_train_split, X_val, y_train_split, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    
    print(f"\nüìä Data Split:")
    print(f"   Training: {len(X_train_split)} samples")
    print(f"   Validation: {len(X_val)} samples")
    print(f"   Test: {len(X_test)} samples")
    
    # Step 2: Train Models
    print("\n" + "=" * 80)
    print("STEP 2: MODEL TRAINING")
    print("=" * 80)
    
    trainer = SimpleModelTrainer()
    results = trainer.train_models(X_train_split, y_train_split, X_val, y_val)
    
    # Step 3: Feature Importance
    print("\n" + "=" * 80)
    print("STEP 3: FEATURE IMPORTANCE ANALYSIS")
    print("=" * 80)
    
    feature_importance = trainer.get_feature_importance()
    if feature_importance is not None:
        print("\nüìä Top 7 Most Important Features:")
        print(feature_importance.to_string(index=False))
    
    # Step 4: Test Performance
    print("\n" + "=" * 80)
    print("STEP 4: TEST PERFORMANCE")
    print("=" * 80)
    
    print("\nüìä Testing on unseen data...")
    
    test_results = {}
    for name in ['Logistic Regression', 'XGBoost']:
        pred, proba = trainer.predict(name, X_test)
        
        from sklearn.metrics import roc_auc_score, accuracy_score
        
        auc = roc_auc_score(y_test, proba)
        acc = accuracy_score(y_test, pred)
        
        test_results[name] = {'auc': auc, 'accuracy': acc}
        
        print(f"\n{name}:")
        print(f"   AUC: {auc:.4f}")
        print(f"   Accuracy: {acc:.4f}")
    
    # Step 5: Summary
    print("\n" + "=" * 80)
    print("‚úÖ SUMMARY - RESUME POINTS DEMONSTRATED")
    print("=" * 80)
    
    print("\n1Ô∏è‚É£ ‚úÖ Predictive System for Loan Recommendations")
    print("   - Used 7 meaningful features from structured financial data")
    print("   - Processed 5,000+ loan applications")
    
    print("\n2Ô∏è‚É£ ‚úÖ ML Models (Logistic Regression, XGBoost)")
    print("   - Logistic Regression AUC: {:.4f}".format(results['Logistic Regression']['auc']))
    print("   - XGBoost AUC: {:.4f}".format(results['XGBoost']['auc']))
    print("   - Both models estimate Probability of Default (PD)")
    
    print("\n3Ô∏è‚É£ ‚úÖ Data-Driven Fintech Solution")
    print("   - Models trained and validated on real-world patterns")
    print("   - Ready for production deployment")
    print("   - Can improve lending efficiency and reduce default risk")
    
    print("\n4Ô∏è‚É£ ‚úÖ Risk Assessment & Recommendation")
    print("   - Both models provide PD scores for each applicant")
    print("   - Can be used for approve/reject decisions")
    
    print("\n" + "=" * 80)
    print("üéâ SYSTEM READY FOR DEMO!")
    print("=" * 80)
    print("\nNext: Run 'streamlit run simple_dashboard.py' to see the interactive dashboard!")
    
    # Save model for dashboard
    import pickle
    with open('models/simple_model.pkl', 'wb') as f:
        pickle.dump(trainer.models['XGBoost']['model'], f)
    print("\nüíæ Model saved to models/simple_model.pkl")

if __name__ == "__main__":
    # Create models directory
    os.makedirs('models', exist_ok=True)
    
    main()

